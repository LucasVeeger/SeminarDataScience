---
title: "Report coursework assignment A - 2021-2022"
subtitle: "CS4125 Seminar Research Methodology for Data Science"
author: "Sara Hacipoglu (5569206),  Lucas Veeger (4459628)"
date: "13/06/2022"
output:
   pdf_document:
      fig_caption: true
      number_sections: true
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


\tableofcontents


# Part 1 - Design and set-up of true experiment 


## The motivation for the planned research 
<!-- (Max 250 words) -->

Energy transition does not only encompass creating new forms of energy, it also concerns how energy is used. And as humans are its grand consumers, they also hold the power to decide where and how it is used.  


## The theory underlying the research  
<!-- (Max 250 words) Preferable based on theories reported in literature-->
How engaged are consumers to consider their footprint when traveling midrange distances (500-2500km, e.g. Amsterdam to Paris is ~500km, Amsterdam to Lissabon is ~2250km). There is growing awareness nowadays about the fact that flying is very harmful to the environment (e.g. flight shame), and that taking the train is a much better alternative in terms of energy consumption. The current problem in Europe is that train traveling has 2 large downsides compared to the highly emissive flight transports. 
    1) It takes a lot longer, often including different connections that have to be completed. 
    2) It is more expensive. 
The first drawback is obvious and will always be existent compared to flying, but it can be reduced. However, the monetary drawback is one that feels counter-intuitive, and one would say it should be possible to facilitate cheaper land transport compared to air transport. But would consumers go for the land alternative given the prices are (more) equal, and would they be making these decisions over environmental reasons or other possible ones (e.g. more comfort?). Also, given a situation where a carbon tax would exist over transport, the carbon emissions would make flying more expensive than any train journey (https://www.dw.com/en/trains-vs-planes-whats-the-real-cost-of-travel/a-45209552).

## Research questions 
<!-- The research question that will be examined in the experiment (or alternatively the hypothesis that will be tested in the experiment) -->

1. Do people generally choose train travel over air travel given price/distance equality?
2. Is there a distance (=? Duration maybe?) limit independent of pricing for which people prefer plane over train travel?


## The related conceptual model 
This model should include:
*Independent variable(s)
  * Travel duration (duration rather than distance, they might not be proportionate on train case - no direct train route etc.)
  * Travel cost
*Dependent variable
  * Choice of travel 
*Mediating variable (at least 1)
  * Travel comfort (duration - comfort - preference)
*Moderating variable (at least 1)
  * Fear for airplanes
  * Financial status, age (for cost)
  * Culture (europe has train travel culture, vs US or other regions)
*Extraneous variable
  * Travel luxury (extraneous variable, influences cost and comfort but is not a study variable) 

Taking the most relevant variables in consideration: we conceptualize the follow graph model:
![The conceptual model](C:/Users/Mirij/Downloads/experiment.png)


## Experimental Design 
<!-- Note that the study should have a true experimental design-->

Subjects are divided in 6 groups.
Reference price y1 is taken as the industry price for flying to a certain distance increased by some margin that corrects for the heavy tax priviliges that are currently enjoyed by flight operators (assuming these will disappear at some point in the future). A train price increase factor of 1.5 is used based on the article  stating UK train travel is around 50% more expensive than air travel (https://www.theguardian.com/environment/2021/jul/14/trains-far-greener-but-much-more-costly-than-planes-analysis-finds). A price decrease factor is determined at 0.75 by the idea that is hard to make railway transport inherently much cheaper (note air transport is mostly cheap for its tax privileges, e.g. no tax on fuel), and it is mostly to see whether an price advantage is extra decisive for subjects. 

- Subject from group 1 are presented the choice: Fly to destination x by plane in z hours for price y1 or by train in z+z+z hours for price y1, or don't travel.
- Subject from group 2 are presented the choice: Fly to destination x by plane in z hours for price y1 or by train in z+z+z hours for price 1.5*y1, or don't travel.
- Subject from group 3 are presented the choice: Fly to destination x by plane in z hours for price y1 or by train in z+z+z hours for price 0.75*y1, or don't travel.
- Subject from group 4, after watching a video about the environmental problems and dangers, are presented the choice : Fly to destination x by plane in z hours for price y1 or by train in z+z+z hours for price y1, or don't travel.
- Subject from group 5, after watching a video about the environmental problems and dangers, are presented the choice : Fly to destination x by plane in z hours for price y1 or by train in z+z+z hours for price 1.5*y1, or don't travel.
- Subject from group 6, after watching a video about the environmental problems and dangers, are presented the choice : Fly to destination x by plane in z hours for price y1 or by train in z+z+z hours for price 0.75*y1, or don't travel.


## Experimental procedure 
<!-- Describe how the experiment will be executed step by step -->
The experiment can be executed decentralized in a real setting (ensuring validity) by setting up a collaboration with a ticket provider, which provides a portal where both train and plane tickets can be bought (probably for a limited amount of trajectories that are properly reachable by both air and train travel (e.g. the destination should not require some extensive other form of travel). 

Once on the platform, subjects will have to fill in a small questionnaire to document some characteristics (e.g. environmental focus and financial means). The questionnaire will start with a paragraph explaining data is anonymously gathered through this portal for experimental reasons, and the prices available might be influenced unexpectedly and might not reflect realistic prices. After filling in the questionnaire, the subject either a video is shown addressing the urgency of environmental awareness, or no video is shown. The underlying algorithm can decide this, preventing a selection bias. The subject is then allowed to search for journeys, for which it is presented always the train and air options together in the same window, with prices based on the experimental design, again selected by the algorithm to ensure the validity of the data collection. The location of the different options content within the window can be varied to reduce the risk of decreasing the reliability. 



## Measures
<!-- Describe the measure that will be used -->

The major measure is travel choice (w.r.t. price, duration and the optional environmental awareness content).
Smaller measures could be decision time, window activity (e.g. using screen monitoring software like Hotjar), moment of decision.


## Participants
<!-- Describe which participants will recruit in the study and how they will be recruited -->
Through social media it is marketed to all kinds of individuals, and through the study it is monitored what target groups require extra input so that marketing focus can be adjusted. The goal is to include any type of person that considers traveling to destinations by air. The participants get real tickets through the collaboration with the ticket provider, so possibly a hype from certain groups of people might start around the platform which could prevented by introducing an application combined with random subject selection for such groups. 


## Suggested statistical analyses
Describe the statistical test you suggest to care out on the collected data
TODOOOOOO
TODOOOOOO
TODOOOOOO


# Part 2 - Generalized linear models

## Question 1 Twitter sentiment analysis (Between groups - single factor) 

### Conceptual model
Make a conceptual model for the following research question: Is there a difference in the sentiment of the tweets related to the different individuals/organisations?

![Conceptual model Twitter sentiment analysis](C:/Users/mirij/Downloads/experiment2.png)

### Collecting tweets, and data preparation
Include the annotated R script (excluding your personal Keys and Access Tokens information), but put echo=FALSE, so code is not included in the output pdf file.


```{r, echo=FALSE, message=FALSE, warning=FALSE, include = FALSE}
#during writing you could add "eval = FALSE",  kntr will than not run this code chunk (take some time do)
# getwd()
# setwd("C:/Users/mirij/Desktop") 
# apple , note use / instead of \, which used by windows
# install.packages("twitteR", dependencies = TRUE)
library(twitteR)
# install.packages("RCurl", dependencies = T)
library(RCurl)
# install.packages("bitops", dependencies = T)
library(bitops)
# install.packages("plyr", dependencies = T)
library(plyr)
# install.packages('stringr', dependencies = T)
library(stringr)
# install.packages("NLP", dependencies = T)
library(NLP)
# install.packages("tm", dependencies = T)
library(tm)
# install.packages("wordcloud", dependencies=T)
# install.packages("RColorBrewer", dependencies=TRUE)
library(RColorBrewer)
library(wordcloud)
# install.packages("reshape", dependencies=T)
library(reshape)
################### functions
  
clearTweets <- function(tweets, excl) {
  
  tweets.text <- sapply(tweets, function(t)t$getText()) #get text out of tweets 
  
  tweets.text = gsub('[[:cntrl:]]', '', tweets.text)
  tweets.text = gsub('\\d+', '', tweets.text)
  tweets.text <- str_replace_all(tweets.text,"[^[:graph:]]", " ") #remove graphic
  
  
  corpus <- Corpus(VectorSource(tweets.text))
  
  corpus_clean <- tm_map(corpus, removePunctuation)
  corpus_clean <- tm_map(corpus_clean, content_transformer(tolower))
  corpus_clean <- tm_map(corpus_clean, removeWords, stopwords("english"))
  corpus_clean <- tm_map(corpus_clean, removeNumbers)
  corpus_clean <- tm_map(corpus_clean, stripWhitespace)
  corpus_clean <- tm_map(corpus_clean, removeWords, c(excl,"http","https","httpst"))
  
  return(corpus_clean)
} 
## capture all the output to a file.
################# Collect from Twitter
# for creating a twitter app (apps.twitter.com) see youtube https://youtu.be/lT4Kosc_ers
#consumer_key <-'your key'
#consumer_scret <- 'your secret'
#access_token <- 'your access token'
#access_scret <- 'your access scret'
source("your_twitter.R") #this file will set my personal variables for my twitter app, adjust the name of this file. use the provide template your_twitter.R
setup_twitter_oauth(consumer_key,consumer_scret, access_token,access_scret) #connect to  twitter app
##### This example uses the following 3 celebrities: Donald Trump, Hillary Clinton, and Bernie Sanders
##  You should replace this with your own celebrities, at least 3, but more preferred 
##  Note that it will take the computer some to collect the tweets
#tweets_T <- searchTwitter("#trump", n=200, lang="en", resultType="recent") #n recent tweets about Donald Trump, in English ( Twitter sometimes modifies number of tweets that you can collect)
#tweets_C <- searchTwitter("#hillary", n=200, lang="en", resultType="recent") #n recent tweets about Hillary Clinton
#tweets_B <- searchTwitter("#bernie", n=200, lang="en", resultType="recent") #n recent tweets about Bernie Sanders
tweets_T <- searchTwitter("#EnergyTransition", n=200, lang="en", resultType="recent") #n recent tweets about Energy Transition, in English ( Twitter sometimes modifies number of tweets that you can collect)
tweets_C <- searchTwitter("#SustainableEnergy", n=200, lang="en", resultType="recent") #n recent tweets about Sustainable Energy
tweets_B <- searchTwitter("#RenewableEnergy", n=200, lang="en", resultType="recent") #n recent tweets about Renewable Energy
######################## WordCloud
### This not requires in the assignment, but still fun to do 
# based on https://youtu.be/JoArGkOpeU0
#corpus_T<-clearTweets(tweets_T, c("trump","amp","realdonaldtrump","trumptrain","donald","trumps","alwaystrump")) #remove also some campain slogans
#wordcloud(corpus_T, max.words=50)
#corpus_C<-clearTweets(tweets_C, c("hillary","amp","clinton","hillarys"))
#wordcloud(corpus_C,  max.words=50)
#corpus_B<-clearTweets(tweets_B, c("bernie", "amp", "sanders","bernies"))
#wordcloud(corpus_B,  max.words=50)
##############################
######################## Sentiment analysis
tweets_T.text <- laply(tweets_T, function(t)t$getText()) #get text out of tweets 
tweets_C.text <- laply(tweets_C, function(t)t$getText()) #get text out of tweets
tweets_B.text <- laply(tweets_B, function(t)t$getText()) #get text out of tweets
#taken from https://github.com/mjhea0/twitter-sentiment-analysis
pos <- scan('positive-words.txt', what = 'character', comment.char=';') #read the positive words
neg <- scan('negative-words.txt', what = 'character', comment.char=';') #read the negative words
source("sentiment3.R") #load algorithm
# see sentiment3.R form more information about sentiment analysis. It assigns a intereger score
# by subtracting the number of occurrence of negative words from that of positive words
analysis_T <- score.sentiment(tweets_T.text, pos, neg)
analysis_C <- score.sentiment(tweets_C.text, pos, neg)
analysis_B <- score.sentiment(tweets_B.text, pos, neg)
#print(analysis_T)
#print(analysis_C)
#print(analysis_B)
sem<-data.frame(analysis_T$score, analysis_C$score, analysis_B$score)
semFrame <-melt(sem, measured=c(analysis_T.score,analysis_C.score, analysis_B.score ))
names(semFrame) <- c("Candidate", "score")
semFrame$Candidate <-factor(semFrame$Candidate, labels=c("Energy Transition", "Sustainable Energy", "Renewable Energy")) # change the labels for your individual/organisation
#The data you need for the analyses can be found in semFrame
#print(semFrame)
```

### Homogeneity of variance analysis
Analyze the homogeneity of variance of sentiments of the tweets of the different individuals/organisations, and provide interpretation

```{r}
#include your code and output in the document
library(car)
leveneTest(semFrame$score, semFrame$Candidate, center = median)
```
The variance across the different organisations is tested using the  Levene's test. The P test results in a value of 0.05258, which above 0.05. Thus, it can be concluded that there is no reason to reject the null hypothesis and we can assume the organisations are similar.
 <!-- Is the variance across the different organisations equal? -->

### Visual inspection Mean and distribution sentiments
Graphically examine the mean and distribution sentiments of tweets for each individual/organisation, and provide interpretation

```{r}
#include your code and output in the document
energyTransition<-semFrame[semFrame$Candidate=="Energy Transition",]
#print(energyTransition)
hist(energyTransition$score, xlab="score")
sustainableEnergy<-semFrame[semFrame$Candidate=="Sustainable Energy",]
#print(sustainableEnergy)
hist(sustainableEnergy$score, xlab="score")
renewableEnergy<-semFrame[semFrame$Candidate=="Renewable Energy",]
#print(renewableEnergy)
hist(renewableEnergy$score, xlab="score")
mysummary <- function(x,npar=TRUE,print=TRUE) {
if (!npar) {
center <- mean(x); spread <- sd(x)
} else {
center <- median(x); spread <- mad(x)
}
if (print & !npar) {
cat("Mean=", center, "\n", "SD=", spread, "\n")
} else if (print & npar) {
cat("Median=", center, "\n", "MAD=", spread, "\n")
}
result <- list(center=center,spread=spread)
return(result)
}
print("Renewable energy:")
d<-mysummary(renewableEnergy$score, FALSE)
print("Sustainable energy:")
d<-mysummary(sustainableEnergy$score, FALSE)
print("Energy transition:")
d<-mysummary(energyTransition$score, FALSE)
boxplot(score ~ Candidate, data=semFrame, main="Sentiment distribution in tweets",
xlab="Organisation", ylab="score")
```
The mean for renewable Energy and sustainable Energy are close to each other. Whereas the mean for energy Transition is significantly lower. The standard deviations for all organisations are similar.

From the boxplot we can see that for all three topics, most of the tweets have a median sentiment around of 0.

### Frequentist approach

#### Linear model
Use a linear model to analyze whether the knowledge to which individual/organisation a tweet relates has a significant impact on explaining the sentiments of the tweets. Assume a Gaussian distribution for the tweet’s sentiments rating. Provide interpretation of results 

```{r}
#include your code and output in the document
model0<- lm(score ~ 1, data = semFrame, na.action = na.exclude) #model without predictor
model1 <- lm(score ~ Candidate, data = semFrame, na.action = na.exclude) #model with predictor
library(pander)
pander(anova(model0, model1),
caption = "Compare if knowledge provide better fit than no knowledge")
pander(anova(model1),
caption = "Effect of organisation type on post test score")
pander(summary(model1))
library(car)
pander(Anova(model1))
```

<!-- The p-value is significantly smaller than 0.05, thus we can reject the null hypothesis. Thus, the organisation gives insight into the sentiment. -->
<!-- From the last column in the summary model, we see that the p-value for sustainableEnergy and renewableEnergy is larger than 0.05. Thus the organisation has no significant impact on the output score. -->
<!-- R-squared is 0.04156, which means that 4% percent of the variance in the observed data can be explained by the model, which is very small. 86% cannot be explained by the model. -->
The F-value in an ANOVA is calculated as: variation between sample means / variation within the samples.
The higher the F-value in an ANOVA, the higher the variation between sample means relative to the variation within the samples. The higher the F-value, the lower the corresponding p-value.
The p-value is 0.0637. This means the difference in sentiment between the organisations would happen 6.735% of the time. As the difference is larger than 0.05, the difference is not statistically significant and is likely due to chance. 

#### Post Hoc analysis
If a model that includes the individual/organisation is better in explaining the sentiments of tweets than a model without such predictor, conduct a post-hoc analysis with e.g. Bonferroni correction, to examine which of individual/organisation tweets differ from the other individual/organisation tweets. Provide interpretation of the results

```{r}
#include your code and output in the document
pairwise.t.test(semFrame$score, semFrame$Candidate, paired = FALSE, p.adjust.method = "bonferroni")
# plot(model1)
pander(tapply(semFrame$score, semFrame$Candidate, shapiro.test)) # test normaliy of each level
leveneTest(semFrame$score, semFrame$Candidate)
```
The p-values corrected with Bonferroni show that the p-values are still above 0.05 between all groups. Therefore, no organisation is better in explaining the sentiment of tweets.

#### Report section for a scientific publication
Write a small section for a scientific publication (journal or a conference), in which you report the results of the analyses, and explain the conclusions that can be drawn in a format commonly used by the scientific community Look at Brightspace for examples papers and guidelines on how to do this. 

<!-- Tweets without the knowledge of each organisation did have significant (t(597) = 12.94, p=3.141e-06) different post test scores (M = 0.395, SD = 0.03145) than the tweets with knowledge of each organisation (energyTransition: M = 0.17500 , SD = 0.8047441), (sustainableEnergy: M = 0.53, SD = 0.7153029) and (renewableEnergy: M = 0.48, SD = 0.7432105).  -->
A Linear Model analysis was conducted to test the difference between cohorts on the organisations. The results found a significant effect (F(2, 597)=2.7101, p < 0.06735) for the cohorts on the organisations.

### Bayesian Approach

#### Model description

Describe the mathematical model fitted on the most extensive model. (hint, look at the mark down file of the lectures to see example on formulate mathematical models in markdown). Assume a Gaussian distribution for the tweet’s sentiments rating. Justify the priors.

Null model:
```{r, echo=FALSE, message=FALSE, warning=FALSE, include = FALSE}
library(rethinking)
m0 <-map2stan(
  alist(
  score ~ dnorm(mu, sigma),
  mu <- a,
  a ~ dnorm(0, 1),
  sigma ~ dnorm(0, 1)
  ), data = semFrame ,iter = 100, chains = 4, cores = 4
)
```

Model model that includes organisation as a factor:
```{r, echo=FALSE, message=FALSE, warning=FALSE, include = FALSE}
m1 <-map2stan(
  alist(
  score ~ dnorm(mu, sigma),
  mu <- a[Candidate],
  a[Candidate] ~ dnorm(0, 1),
  sigma ~ dnorm(0, 1)
  ), data = semFrame ,iter = 100, chains = 4, cores = 4
)
```
The chosen priors are 0, as it is a neutral value for sentiment.

#### Model comparison

Conduct model analysis and provide brief interpretation of the results

```{r}
#include your code and output in the document
 
compare(m0, m1, func=WAIC)
precis(m1, depth=2, prob = .95)
```

The WAIC for model 1 is smaller than the WAIC of model 0, thus we can say that model 1 has improved from model 0. 

#### Comparison individual/organisation pair

Compare sentiments of individual/organisation pairs and provide a brief interpretation (e.g. CIs)

```{R}
precis(m1, depth=2, prob = .95)
```
EnergyTransition has the most distinct mean compared to sustainableEnergy and renewableEnergy.


## Question 2 - Website visits (between groups - Two factors)

### Conceptual model
Make a conceptual model underlying this research question

![Conceptual model Twitter sentiment analysis](C:/Users/mirij/Downloads/experiment3.png)

### Visual inspection
Graphically examine the variation in page mean number of visits for the four different conditions


```{r, echo=FALSE, message=FALSE, warning=FALSE}
library(devtools)
library(ggplot2)
library(rcompanion)
library(dplyr)
library(gmodels)
library(pander)
library(car)
#setwd("C:/Users/mirij/Desktop")
setwd("C:/Users/ilgin/OneDrive/Documents/GitHub/SeminarDataScience/assignmentA")
webvisit<- read.csv("webvisit2.csv")
#levenes test
pander(leveneTest(webvisit$pages, interaction(webvisit$version , webvisit$portal)),
caption = "Levenes Test on homogeneity of variance accross 4 conditions")
```
Levenes test found significant difference between the 4 conditions with a p-value less than 0.05. The two by two experiment consists of factors version and portal. 


```{r, echo=FALSE, message=FALSE, warning=FALSE}
webvisit$versionF <- factor(webvisit$version, levels=c(0,1), labels = c(0,1))
webvisit$portalF <- factor(webvisit$portal, levels=c(0,1), labels = c(0,1))
bar_mean_var <- ggplot(webvisit, aes(versionF , pages, fill = portalF))
bar_mean_var + stat_summary(fun = mean, geom = "bar", position="dodge")
```


The two figures shows the mean page visit number for each condition. We observe a significant mean difference of greater than 10 in page visit between consumers and companies portal entries when website version condition is set to new. The observed difference of means is less between consumer and company portal conditions when version is set to old. 

Similarly there is a higher difference in page visit means between new and old website version entries for the condition where the portal is a company portal.

### Frequentist Approach

#### Model analysis
Conduct a model analysis, to examine the added values of adding 2 factors and interaction between the factors in the model to predict page visits, and include brief interpretation of the results.


```{r, echo=TRUE, message=FALSE, warning=FALSE}
model0 <- glm(pages ~ 1 , family='poisson', data = webvisit, na.action = na.exclude)
model1 <- glm(pages ~ versionF , family='poisson', data = webvisit, na.action = na.exclude)
model2 <- glm(pages ~ portalF , family='poisson', data = webvisit, na.action = na.exclude)
model3 <- glm(pages ~ versionF + portalF ,family='poisson',  data = webvisit, na.action = na.exclude)
model4 <- glm(pages ~ versionF + portalF + versionF:portalF ,family='poisson', data = webvisit, na.action = na.exclude)
```

```{r, echo=TRUE, message=FALSE, warning=FALSE}
anova(model0,model1,test="Chisq")
       #caption = "Version as main effect on visited page count")
```
The p-value is 2.2e-16, that is less than 0.01.  This implies we reject the null hypothesis in favor that model0 is better, in favor of model1. Compared to model0 which only takes the intercept, model2 that takes version as a factor is a better fit. 

```{r, echo=TRUE, message=FALSE, warning=FALSE}
pander(anova(model0,model2,test="Chisq"),
       caption = "Portal as main effect on visited page count")
```
The p-value is 1.06e-102, that is less than 0.01.  This implies we reject the null hypothesis that model0 models is better, in favor of model2. Compared to model0 which only takes the intercept, model2 that takes portal as a factor is a better fit. 
```{r, echo=TRUE, message=FALSE, warning=FALSE}
pander(anova(model3,model4,test="Chi"),
       caption = "Interaction effect on top of two main effects(portal and version)")
```
The p-value is 3.24e-191, that is less than 0.01.  This implies we reject the null hypothesis that model3 is better, in favor of model4. Compared to model3 which takes the both version and portal as predictors, model4 that takes both as well as their interaction effect is a better fit. 

```{r, echo=TRUE, message=FALSE, warning=FALSE}
pander(anova(model4,test="Chisq"),caption="Effect of version, portal and interaction effect on number of pages visited ")
```

The extension made by both model 1 and model 2  that take version and portal as main effects respectively show
improvement over the intercept model with significant p values. Furthermore model 4 takes the interaction of the two main effects version and portal on top of the two main effects. Extension made by model 4 shows improvement over model 3 with a significant p value. This justifies further exploration of model 4. 

Two-way Anova results of model4 indicate a p-value of 3.24e-191 for the interaction between version and portal. This value is statistically significant at alpha level 0.05. Similarly, the p-values for the effect of version and portal are statistically significant.
These results indicate that version, portal and their interaction factors have a statistically significant effect on web page visit count. 


```{r, echo=TRUE, message=FALSE, warning=FALSE}
library(AICcmodavg)
models <-list(model0, model1, model2, model3, model4)
model.names <-c("model0","model1","model2","model3","model4")
pander(aictab(cand.set = models, modnames=model.names)) #model4 is best
```
From the AIcc analysis we can see that the best model is model 4, the interaction model – the model that includes both portal and version parameters as well as their interactions (pages ~ version + portal + version:portal). In this case, model 4 is the best model as it contains more than 99% of the total explanation that can be found in the full set of models and has the  lowest AIC score. The next-best model carries much less than 1% of the cumulative model weight.  

#### Assumption analysis
For the best fitting model, examine graphically the distribution of the residuals. Also examine the residuals of the same model but then assuming a Gaussian distribution for the number of page visits. Give a brief interpretation about Poisson and Gaussian distribution assumption. 

```{r, echo=TRUE, message=FALSE, warning=FALSE}
hist(resid(model4))
```
```{r, echo=TRUE, message=FALSE, warning=FALSE}
model4_gaussian <- glm(pages ~ versionF + portalF + versionF:portalF ,family='gaussian', data = webvisit, na.action = na.exclude)
hist(resid(model4_gaussian))
```
The histograms of residuals for both Gaussian and Poisson distribution assumptions appear roughly normally distributed. This implies that for both cases, the normal distribution of error assumptions are valid. The residual value has more variance in the Gaussian model as they range from (-15,15). Residuals in Poisson model histogram show lower variance with values in the range (-3,3), suggesting Poisson assumption could be more suitable for this dataset. 

```{r, echo=TRUE, message=FALSE, warning=FALSE}
plot(model4)
```

```{r, echo=TRUE, message=FALSE, warning=FALSE}
plot(model4_gaussian)
```

For both Gaussian and Poisson assumptions, residuals are mostly fitted on y=x line on Normal Q-Q plots. There is slightly more divergence in the tails of the fixed line on the Normal Q-Q plot for Poisson assumption compared to the Gaussian. 

#### Simple effect analysis
If the analysis shows a significant two-way interaction effect, conduct a Simple Effect analysis to explore this interaction effect in more detail.It helps first to look at the means of different conditions in a figure. Provide brief interpretation of the results.

The model analysis showed a significant two-way interaction effect on top of the significant main effects version and portal. 

```{r, echo=TRUE, message=FALSE, warning=FALSE}
webvisit$simpeff <- interaction(webvisit$portalF, webvisit$versionF)
levels(webvisit$simpeff) 
contrastOld <-c(1,-1,0,0) 
contrastNew <-c(0,0,1,-1) 
SimpleEff <- cbind(contrastOld,contrastNew)
contrasts(webvisit$simpeff) <- SimpleEff
simpleEffectModel <-glm(pages ~ simpeff , family="poisson", data = webvisit, na.action = na.exclude) 
pander(summary.glm(simpleEffectModel))
```
A significant difference can be found in result contrastOld and contrastComplex.When page visit counts are compared with the old version contrast, we observe a significant difference between customer and company portal implementations. Similarly, when page visit counts are compared with new version contrast, a significant difference between customer and company portal implementations can be observed. 

#### Report section for a scientific publication

A linear model assuming Poisson distribution for website page visit count was fitted on the impact of number of pages visited on the webserver of company X, taking website version and website portal entry type as independent variables, and including a two-way interaction between these variables. 

The analysis found a significant main effect (X2(1, 998) = 2165, p. < 0.01) for the website version, significant main effect(X2(1, 997) = 1805, p. < 0.01)  for website portal entry. The analysis also found a significant two-way interaction effect ( F (1, 996) = 934.5, p.< 0.01) between these two variables.

A simple Effect analysis further examined the two-way interaction. It revealed a significant (z = 16.18, p. < 0.01)
difference for portal entry type of the website with the old website version, as well as a significant effect (z = -30.32,
p.<0.01) was found for portal entry type with the new website version implementation.



### Bayesian Approach

#### Model description

Describe the mathematical model fitted on the most extensive model. (hint, look at the mark down file of the lectures to see example on formulate mathematical models in markdown). Assume Poisson distribution for the number of page visits. Justify the priors.



$pages \sim Pois(\lambda)$ [likelihood]

$\log(lambda) = a + b\times version + c\times portal + d\times portal\times version$  [linear model]

$a \sim Norm(25, 25)$ [$a$ prior]

$b,c \sim uniform(0, 1)$ [$b$,$c$ priors]
$d \sim Norm(0, 10)$ [$d$  prior]


For parameter a, which represents the intercept, we expect the parameter to be anywhere from 0 to 50 as page visit values vary in the data. As these are not hard bounds, we will be using normal(25,25). On the other hand, parameters b and c represent portal and version factors, which are known to be values either 0 or 1. Therefore, we prefer a uniform prior for these parameters. Parameter d reflects the interaction effect for portal and version factors, for which we preferred a normal(0,10) weakly informative prior, as we do not know about the distribution for the interactive effect parameter 

#### Model comparison


```{r message=FALSE, warning=FALSE, cache=TRUE, include=FALSE, results='hide'}
wvbayes <- subset(webvisit, select = c(pages,version, portal ))
wvbayes$portalN <- as.numeric(wvbayes$portal)
wvbayes$versionN <- as.numeric(wvbayes$version)
library(rethinking)
m0 <-map2stan(
  alist(
    pages ~ dpois(lambda),
    log(lambda) <- a,
    a ~ dnorm(25,25)
  ), data = wvbayes ,iter = 2000, chains = 4, cores = 4
)
m1 <-map2stan(
  alist(
    pages ~ dpois(lambda),
    log(lambda) <- a + b*versionN,
    a ~ dnorm(25,25),
    b ~ dunif(0, 1)
  ), data = wvbayes ,iter = 2000, chains = 4, cores = 4
)
m2 <-map2stan(
  alist(
    pages ~ dpois(lambda),
    log(lambda) <- a + c*portalN,
    a ~ dnorm(25,25),
    c ~ dunif(0, 1)
  ), data = wvbayes,iter = 2000, chains = 4, cores = 4
)
m3 <-map2stan(
  alist(
    pages ~ dpois(lambda),
    log(lambda) <- a + b*versionN + c*portalN,
    a ~ dnorm(25,25),
    b ~ dunif(0, 1),
    c ~ dunif(0, 1)
  ), data = wvbayes,iter = 2000, chains = 4, cores = 4
)
m4 <-map2stan(
  alist(
    pages ~ dpois(lambda),
    log(lambda) <- a + b*versionN + c*portalN + d*versionN*portalN,
    a ~ dnorm(25,25),
    b ~ dunif(0, 1),
    c ~ dunif(0, 1),
    d ~ dnorm(0, 10)
  ), data = wvbayes,iter = 2000, chains = 4, cores = 4
)
```

```{r}
compare(m0,m1,m2,m3,m4)
```
The compare function shows that m4 has the smallest WAIC value, thus the best out-of-sample fit. 

```{r}
precis(m4,prob= .95)
```
Looking at 95% credible intervals of the parameters of model 4, the credible values of coefficient b for version predictor, coefficient c portal predictor and coefficient d interaction predictor are not including null. 
As these interval do not contain the value zero, this leads to the rejection of the null hypothesis that coefficients b=0, c=0, d=0. 
 
# Part 3 - Multilevel model

## Visual inspection
Use graphics to inspect the distribution of the score, and relationship between session and score
```{r}
#include your code and output in the document

setwd("C:/AAASweepsta/MSc. Computer Science/Seminar Data Science/Coursework/Coursework A") 

set <- read.csv("set1.csv")

# Distribution of the score
boxplot(set$score)

# Relationship between session and score
boxplot(score ~ session, data=set, main="Score",
xlab="Session", ylab="Score over sessions")

```


## Frequentist approach

### Multilevel analysis
Conduct multilevel analysis and calculate 95% confidence intervals thereby assuming a Gaussian distribution for the scores, determine:

* If session has an impact on people score
* If there is significant variance between the participants in their score


```{r}
#include your code and output in the document
library(nlme)
# m <- lme(score ~ session,random = ~subject|id_c,data=set, method="ML")


# don't try this at home
intercept <- gls(score ~ 1, data=set, method="ML", na.action = na.exclude)

# random intercept
m0_randomIntercept <- lme(score ~ 1,random = ~1 | subject,method = "ML",data=set, na.action = na.exclude, control = list(opt="optim"))

# fixed effect 
# session_m1 <- lme(score ~ session,random = ~1 | subject,method = "ML",data=set)
m1_session <-  update(m0_randomIntercept, .~. + session)
# random effect
m2_ses_subj <- update(m1_session, random = ~session|subject)

summary(m0_randomIntercept)
summary(m1_session)
summary(m2_ses_subj)
```
```{r}
ARModel <- update(m2_ses_subj, correlation = corAR1(0, form = ~session|subject))
summary(ARModel)


```
```{r}
anova(intercept, m0_randomIntercept, m1_session, m2_ses_subj, ARModel)
```
```{r}
sessionsQuadratic <- update(ARModel, .~. + I(session^2))
sessionsCubic <- update(sessionsQuadratic, .~. + I(session^3))
anova(intercept, m0_randomIntercept, m1_session, m2_ses_subj, ARModel, sessionsQuadratic, sessionsCubic)
anova(ARModel, sessionsQuadratic, sessionsCubic)
```


```{r}

library(pander)
pander(anova(m0, m1),
caption = "Compare if knowledge provide better fit than no knowledge")

pander(anova(m0),
caption = "Effect of organisation type on post test score")

pander(summary(m1))

library(car)
pander(Anova(m1))

intervals(m0, level = 0.95)
intervals(m1,level = 0.95)


```

### Report section for a scientific publication
Write a small section for a scientific publication, in which you report the results of the analyses, and explain the conclusions that can be drawn.

## Bayesian approach

### Model description

Describe the mathematical model fitted on the most extensive model. (hint, look at the mark down file of the lectures to see example on formulate mathematical models in markdown).  Assume a Gaussian distribution for the scores. Justify the priors.

### Model comparison

Compare models with with increasing complexity. 

```{r}
#include your code and output in the document
library(rethinking)

# fixed intercept
m0 <- ulam(
  alist(
    #Likelihood
    score ~dnorm(mu, sigma),
    
    #Linear model 
    mu <- a,
    
    # fixed priors
    a~dnorm(5.5, 2),
    sigma ~ dcauchy(0,1)
  ), data = set, iter = 10000, chains = 4, cores = 4, log_lik = TRUE
)

```

```{r}
# random intercept
m1 <- ulam(
  alist(
    #Likelihood
    score ~dnorm(mu, sigma),
    
    #Linear model 
    mu <- a + a_subject[subject], 
    
    # adaptive prior
    a_subject[subject] ~ dnorm(0, sigma_subject),
    
    # hyper prior
    sigma_subject ~ dcauchy(0, 1),
    
    # fixed priors
    a ~ dnorm(5.5, 2),
    sigma ~ dcauchy(0,1)
  ), data = set, iter = 10000, chains = 4, cores = 4, 
    log_lik = TRUE, control=list(adapt_delta=0.99)
)

```

```{r}
# Fixed effect time
m2 <- ulam(
  alist(
    #Likelihood
    score ~dnorm(mu, sigma),
    
    #Linear model 
    mu <- a + a_subject[subject] + b*session, 
    
    # adaptive prior
    a_subject[subject] ~ dnorm(0, sigma_subject),
    
    # hyper prior
    sigma_subject ~ dcauchy(0, 1),
    
    # fixed priors
    a ~ dnorm(5.5, 2),
    b ~ dnorm(0, 1),
    sigma ~ dcauchy(0,1)
  ), data = set, iter = 10000, chains = 4, cores = 4, 
    log_lik = TRUE, control=list(adapt_delta=0.99)
)


```

```{r}
# Random slope
m3 <- ulam(
  alist(
    #Likelihood
    score ~dnorm(mu, sigma),
    
    #Linear model 
    mu <- a + a_subject[subject] + 
      (b + b_subject[subject])*session, 
    
    # adaptive prior
    a_subject[subject] ~ dnorm(0, a_sigma_subject),
    b_subject[subject] ~ dnorm(0, b_sigma_subject),
    
    # hyper prior
    c(a_sigma_subject, b_sigma_subject) ~ dcauchy(0, 1),
    
    # fixed priors
    a ~ dnorm(5.5, 2),
    b ~ dnorm(0, 1),
    sigma ~ dcauchy(0,1)
  ), data = set, iter = 10000, chains = 4, cores = 4, 
    log_lik = TRUE, control=list(adapt_delta=0.99), 
    max_treedepth = 15
)

```

```{r}
# Correlation
m4 <- ulam(
  alist(
    #Likelihood
    score ~dnorm(mu, sigma),
    
    #Linear model 
    mu <- a + a_subject[subject] + 
      b_subject[subject]*session, 
    
    # adaptive prior
    c(a_subject, b_subject)[subject] ~ multi_normal(c(a,b), 
                                                    Rho, sigma_subject),
    
    # hyper prior
    sigma_subject ~ dcauchy(0, 1),
    Rho ~ dlkjcorr(2),
    
    # fixed priors
    a ~ dnorm(5.5, 2),
    b ~ dnorm(0, 1),
    sigma ~ dcauchy(0,1)
  ), data = set, iter = 10000, chains = 4, cores = 4, 
    log_lik = TRUE, control=list(adapt_delta=0.99), 
    max_treedepth = 15
)
```


```{r}
# Quadratic
set$session2 <- set$session*set$session

m5 <- ulam(
  alist(
    #Likelihood
    score ~dnorm(mu, sigma),
    
    #Linear model 
    mu <- a_subject[subject] + 
      b_subject[subject]*session + 
      c*session2, 
    
    # adaptive prior
    c(a_subject, b_subject)[subject] ~ multi_normal(c(a,b), 
                                                    Rho, sigma_subject),
    
    # hyper prior
    sigma_subject ~ dcauchy(0, 1),
    Rho ~ dlkjcorr(2),
    
    # fixed priors
    a ~ dnorm(5.5, 2),
    c(b,c) ~ dnorm(0, 1),
    sigma ~ dcauchy(0,1)
  ), data = set, iter = 10000, chains = 4, cores = 4, 
    log_lik = TRUE, control=list(adapt_delta=0.99), 
    max_treedepth = 15
)
```

```{r}
# Cubic
set$session3 <- set$session2*set$session

m6 <- ulam(
  alist(
    #Likelihood
    score ~dnorm(mu, sigma),
    
    #Linear model 
    mu <- a_subject[subject] + 
      b_subject[subject]*session + 
      c*session2 + d*session3, 
    
    # adaptive prior
    c(a_subject, b_subject)[subject] ~ multi_normal(c(a,b), 
                                                    Rho, sigma_subject),
    
    # hyper prior
    sigma_subject ~ dcauchy(0, 1),
    Rho ~ dlkjcorr(2),
    
    # fixed priors
    a ~ dnorm(5.5, 2),
    c(b,c,d) ~ dnorm(0, 1),
    sigma ~ dcauchy(0,1)
  ), data = set, iter = 10000, chains = 4, cores = 4, 
    log_lik = TRUE, control=list(adapt_delta=0.99), 
    max_treedepth = 15
)
```


### Estimates examination

Examine the estimate of parameters of the model with best fit, and provide a brief interpretation.


```{r}
#include your code and output in the document
compare(m0,m1,m2,m3,m4,m5,m6)
```


